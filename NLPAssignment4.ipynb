{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPAssignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48V_DA9sPDJi"
      },
      "source": [
        "# Assignment 4\n",
        "<ul>\n",
        "<li>Tokenize and tag all the workds in the sentence with Penn Treebank Tagset.</li>\n",
        "<li>Evaluate unigram tagger using brown corpus.</li>\n",
        "<li>Train and test unigram tagger using brown corpus.</li>\n",
        "<li>Measure precision, recall, f1-score and support.</li>\n",
        "<li>Perform the above operations for bigram & trigram tagger. Evaluate them.</li>\n",
        "<li>Combine N-gram taggers and try to achieve maximum accuracy.</li>\n",
        "<li>Use Brill Tagger to achieve better accuracy than combined taggers.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv7NLNuhO1y-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7046f72a-524d-4281-d31b-153a8f14d8a7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiUXvhWXO7Ip"
      },
      "source": [
        "sentence = \"The greatest glory in living lies not in never falling, but in rising every time we fall.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBg6awU0PAnI"
      },
      "source": [
        "from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwKuUsb_R9jo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6cb82a41-6fa5-4fe8-d6fa-47ed2b90417e"
      },
      "source": [
        "print(nltk.pos_tag(word_tokenize(sentence)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'DT'), ('greatest', 'JJS'), ('glory', 'NN'), ('in', 'IN'), ('living', 'VBG'), ('lies', 'NNS'), ('not', 'RB'), ('in', 'IN'), ('never', 'RB'), ('falling', 'VBG'), (',', ','), ('but', 'CC'), ('in', 'IN'), ('rising', 'VBG'), ('every', 'DT'), ('time', 'NN'), ('we', 'PRP'), ('fall', 'VBP'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYGhgsaFSCDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "5df49a7e-cae4-4eeb-eb0f-8810b5d44a4b"
      },
      "source": [
        "for i in nltk.pos_tag(word_tokenize(sentence)):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('The', 'DT')\n",
            "('greatest', 'JJS')\n",
            "('glory', 'NN')\n",
            "('in', 'IN')\n",
            "('living', 'VBG')\n",
            "('lies', 'NNS')\n",
            "('not', 'RB')\n",
            "('in', 'IN')\n",
            "('never', 'RB')\n",
            "('falling', 'VBG')\n",
            "(',', ',')\n",
            "('but', 'CC')\n",
            "('in', 'IN')\n",
            "('rising', 'VBG')\n",
            "('every', 'DT')\n",
            "('time', 'NN')\n",
            "('we', 'PRP')\n",
            "('fall', 'VBP')\n",
            "('.', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jbsxjdGSxJg"
      },
      "source": [
        "## Let's do some Unigram tagging!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhM2jhy6TN-a"
      },
      "source": [
        "from nltk.tag import UnigramTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUlU2XwTWhw"
      },
      "source": [
        "from nltk.corpus import brown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs3c_yDlMILB"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcbrmzHsTaQN"
      },
      "source": [
        "tagged_sents = brown.tagged_sents(categories=\"news\", tagset=\"universal\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuU-rl7upzDd"
      },
      "source": [
        "i = int(len(tagged_sents)*0.80)\n",
        "\n",
        "train_sents = tagged_sents[:i]\n",
        "test_sents = tagged_sents[i:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiTxVeSJMigv"
      },
      "source": [
        "uni_tag = UnigramTagger(train_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYyAOpgoMwwJ"
      },
      "source": [
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdwlsGtIMyvY"
      },
      "source": [
        "accuracy = uni_tag.evaluate(test_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfL_R8waM2-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec3a93f7-3867-4a6a-b4ce-f0aef66b9af2"
      },
      "source": [
        "print(f\"Accuracy of the unigram tagger is {round(accuracy, 3)}!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the unigram tagger is 0.836!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNHUmPPlM9-u"
      },
      "source": [
        "generating a report for the trained tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_CqCk13NPEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "a2b9a2c4-e9dc-4713-ba57-6408154f5b71"
      },
      "source": [
        "tagged_test_sents = uni_tag.tag_sents([[token for token, tag in sent] for sent in test_sents])\n",
        "old = [str(tag) for sentence in test_sents for token, tag in sentence]\n",
        "pred = [str(tag) for sentence in tagged_test_sents for token, tag in sentence]\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(old, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       1.00      1.00      1.00      2686\n",
            "         ADJ       0.88      0.71      0.78      1582\n",
            "         ADP       0.94      0.91      0.92      2582\n",
            "         ADV       0.95      0.72      0.82       863\n",
            "        CONJ       0.99      0.99      0.99       600\n",
            "         DET       1.00      0.99      0.99      2412\n",
            "        NOUN       0.96      0.70      0.81      5457\n",
            "         NUM       0.99      0.81      0.89       464\n",
            "        None       0.00      0.00      0.00         0\n",
            "        PRON       1.00      0.94      0.97       558\n",
            "         PRT       0.69      0.93      0.79       543\n",
            "        VERB       0.96      0.80      0.87      2981\n",
            "           X       1.00      0.03      0.06        31\n",
            "\n",
            "    accuracy                           0.84     20759\n",
            "   macro avg       0.87      0.73      0.76     20759\n",
            "weighted avg       0.96      0.84      0.89     20759\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV-k3jonOAWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37d19075-8b9f-42f8-d993-dbfd9696275b"
      },
      "source": [
        "uni_tag.evaluate(test_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8356375547955104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkvrW3jxOj89"
      },
      "source": [
        "## Let's do the same with Bigrams and Trigrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2sXf9f4PhCL"
      },
      "source": [
        "importing, training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVQAtzcfPEAF"
      },
      "source": [
        "from nltk.tag import BigramTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GExDbnBQBf3"
      },
      "source": [
        "tagged_sents = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
        "\n",
        "i = int(len(tagged_sents)*0.80)\n",
        "\n",
        "train_sents = tagged_sents[:i]\n",
        "test_sents = tagged_sents[i:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHrnjvP_PXpg"
      },
      "source": [
        "bi_tag = BigramTagger(train_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaCW4eq9Pkub"
      },
      "source": [
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-bu7B5MPeh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcda27e0-e2f9-40f1-85a3-7f11e4a048a9"
      },
      "source": [
        "print(f\"The accuracy of bigram tagger is {bi_tag.evaluate(test_sents)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of bigram tagger is 0.12866708415626957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW1IPtX4PwiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "0e775b39-6127-48ac-a1c3-899bc1fbac41"
      },
      "source": [
        "tagged_test_sents = bi_tag.tag_sents([[token for token, tag in sent] for sent in test_sents])\n",
        "old = [str(tag) for sentence in test_sents for token, tag in sentence]\n",
        "pred = [str(tag) for sentence in tagged_test_sents for token, tag in sentence]\n",
        "\n",
        "print(metrics.classification_report(old, pred, zero_division=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       1.00      0.10      0.18      2686\n",
            "         ADJ       0.89      0.11      0.19      1582\n",
            "         ADP       0.93      0.14      0.25      2582\n",
            "         ADV       0.92      0.15      0.26       863\n",
            "        CONJ       0.99      0.12      0.21       600\n",
            "         DET       0.99      0.22      0.37      2412\n",
            "        NOUN       0.98      0.09      0.16      5457\n",
            "         NUM       0.97      0.14      0.24       464\n",
            "        None       0.00      1.00      0.00         0\n",
            "        PRON       1.00      0.26      0.41       558\n",
            "         PRT       0.77      0.15      0.24       543\n",
            "        VERB       0.99      0.13      0.22      2981\n",
            "           X       1.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.13     20759\n",
            "   macro avg       0.88      0.20      0.21     20759\n",
            "weighted avg       0.97      0.13      0.22     20759\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdI8RmVaU58p"
      },
      "source": [
        "importing, training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6YtIQN3VH1i"
      },
      "source": [
        "from nltk.tag import TrigramTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTwSoM-wVP88"
      },
      "source": [
        "tagged_sents = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
        "\n",
        "i = int(len(tagged_sents)*0.80)\n",
        "\n",
        "train_sents = tagged_sents[:i]\n",
        "test_sents = tagged_sents[i:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSyDvowtVQLy"
      },
      "source": [
        "tri_tag = TrigramTagger(train_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWa8glQLXMZp"
      },
      "source": [
        "testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88TVIphuVT0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "beef06bd-e3c4-4c3f-8d00-dc5deded69b2"
      },
      "source": [
        "print(f\"The accuracy of trigram tagger is {tri_tag.evaluate(test_sents)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of trigram tagger is 0.07408834722289127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NrgX8dXVbn-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "1fbea506-824b-4549-e5e6-02393ecf0007"
      },
      "source": [
        "tagged_test_sents = tri_tag.tag_sents([[token for token, tag in sent] for sent in test_sents])\n",
        "old = [str(tag) for sentence in test_sents for token, tag in sentence]\n",
        "pred = [str(tag) for sentence in tagged_test_sents for token, tag in sentence]\n",
        "\n",
        "print(metrics.classification_report(old, pred, zero_division=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       1.00      0.06      0.12      2686\n",
            "         ADJ       0.89      0.05      0.09      1582\n",
            "         ADP       0.96      0.09      0.16      2582\n",
            "         ADV       0.92      0.09      0.17       863\n",
            "        CONJ       1.00      0.09      0.17       600\n",
            "         DET       0.99      0.16      0.28      2412\n",
            "        NOUN       0.99      0.03      0.07      5457\n",
            "         NUM       0.97      0.07      0.13       464\n",
            "        None       0.00      1.00      0.00         0\n",
            "        PRON       0.99      0.18      0.31       558\n",
            "         PRT       0.84      0.10      0.17       543\n",
            "        VERB       0.99      0.06      0.11      2981\n",
            "           X       1.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.07     20759\n",
            "   macro avg       0.89      0.15      0.14     20759\n",
            "weighted avg       0.97      0.07      0.13     20759\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di4ovpssVweG"
      },
      "source": [
        "## Let's combine the taggers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9qc_-oCXZfx"
      },
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    \n",
        "    return backoff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27kpIUrIYR0O"
      },
      "source": [
        "tagged_sents = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
        "\n",
        "i = int(len(tagged_sents)*0.80)\n",
        "\n",
        "train_sents = tagged_sents[:i]\n",
        "test_sents = tagged_sents[i:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdMFPoB9Y3xW"
      },
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "\n",
        "back_tagger = DefaultTagger('NN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ml-m77Ym_b"
      },
      "source": [
        "combined_tagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], backoff=back_tagger)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbkDQeNUZFue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed6bff81-da9a-4634-de95-083e719a209b"
      },
      "source": [
        "print(combined_tagger.evaluate(test_sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8359747579363168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0yudKM9ZU6t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "3078f610-137e-4b2f-c301-7c79bad729cf"
      },
      "source": [
        "tagged_test_sents = combined_tagger.tag_sents([[token for token, tag in sent] for sent in test_sents])\n",
        "old = [str(tag) for sentence in test_sents for token, tag in sentence]\n",
        "pred = [str(tag) for sentence in tagged_test_sents for token, tag in sentence]\n",
        "\n",
        "print(metrics.classification_report(old, pred, zero_division=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       1.00      1.00      1.00      2686\n",
            "         ADJ       0.89      0.69      0.78      1582\n",
            "         ADP       0.93      0.92      0.92      2582\n",
            "         ADV       0.93      0.75      0.83       863\n",
            "        CONJ       0.99      0.99      0.99       600\n",
            "         DET       1.00      0.99      0.99      2412\n",
            "          NN       0.00      1.00      0.00         0\n",
            "        NOUN       0.96      0.70      0.81      5457\n",
            "         NUM       0.99      0.81      0.89       464\n",
            "        PRON       0.98      0.95      0.97       558\n",
            "         PRT       0.70      0.81      0.75       543\n",
            "        VERB       0.97      0.81      0.88      2981\n",
            "           X       1.00      0.03      0.06        31\n",
            "\n",
            "    accuracy                           0.84     20759\n",
            "   macro avg       0.87      0.80      0.76     20759\n",
            "weighted avg       0.95      0.84      0.89     20759\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNPhiDiZZdpg"
      },
      "source": [
        "## Let's use brill tagger in order to achieve accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnubURPizJCK"
      },
      "source": [
        "## Training the brill trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE9YtfooZzMr"
      },
      "source": [
        "from nltk.tag import brill, brill_trainer\n",
        "\n",
        "def train_brill_tagger(initial_tagger, train_sents, **kwargs):\n",
        "    templates = [\n",
        "                 brill.Template(brill.Pos([-1])),\n",
        "                 brill.Template(brill.Pos([1])),\n",
        "                 brill.Template(brill.Pos([-2])),\n",
        "                 brill.Template(brill.Pos([2])),\n",
        "                 brill.Template(brill.Pos([-2, -1])),\n",
        "                 brill.Template(brill.Pos([1, 2])),\n",
        "                 brill.Template(brill.Pos([-3, -2, -1])),\n",
        "                 brill.Template(brill.Pos([1, 2, 3])),\n",
        "                 brill.Template(brill.Pos([-1]), brill.Pos([1])),\n",
        "                 brill.Template(brill.Word([-1])),\n",
        "                 brill.Template(brill.Word([1])),\n",
        "                 brill.Template(brill.Word([-2])),\n",
        "                 brill.Template(brill.Word([2])),\n",
        "                 brill.Template(brill.Word([-2, -1])),\n",
        "                 brill.Template(brill.Word([1, 2])),\n",
        "                 brill.Template(brill.Word([-3, -2, -1])),\n",
        "                 brill.Template(brill.Word([1, 2, 3])),\n",
        "                 brill.Template(brill.Word([-1]), brill.Word([1])),\n",
        "    ]\n",
        "\n",
        "    trainer = brill_trainer.BrillTaggerTrainer(initial_tagger, templates, deterministic=True)\n",
        "\n",
        "    return trainer.train(train_sents, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVwls2X2zGYC"
      },
      "source": [
        "## Using the trained tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZUgtBrc0Gy6"
      },
      "source": [
        "#!pip install tag_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Ni8G81zPkT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b20de6c9-2a25-4a16-e083-bafaaaf0c865"
      },
      "source": [
        "from nltk.tag import brill, brill_trainer\n",
        "from nltk.tag import DefaultTagger\n",
        "from nltk.corpus import brown\n",
        "#from tag_util import train_brill_tagger\n",
        "\n",
        "default_tag = DefaultTagger('NN')\n",
        "\n",
        "tagged_sents = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
        "\n",
        "i = int(len(tagged_sents)*0.80)\n",
        "\n",
        "train_sents = tagged_sents[:i]\n",
        "test_sents = tagged_sents[i:]\n",
        "\n",
        "initial_tag = backoff_tagger(\n",
        "    train_sents, [UnigramTagger, BigramTagger, TrigramTagger],\n",
        "    backoff = default_tag\n",
        ")\n",
        "\n",
        "a = initial_tag.evaluate(test_sents)\n",
        "\n",
        "print(\"Accuracy of Inital Tag : \", a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Inital Tag :  0.8359747579363168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQzT54s21yrZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7684f296-8df0-4794-9d85-e28c629184ad"
      },
      "source": [
        "brill_tag = train_brill_tagger(initial_tag, train_sents)\n",
        "b = brill_tag.evaluate(test_sents)\n",
        "\n",
        "print(\"Accuracy of brill_tag : \", b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of brill_tag :  0.8396358206079291\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}